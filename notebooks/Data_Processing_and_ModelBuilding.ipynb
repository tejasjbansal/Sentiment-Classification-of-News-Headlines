{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data_Processing_and_ModelBuilding.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZnTuGpR9kks",
        "outputId": "bf5c9e74-ddce-4513-de61-09aacb60c950"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/grive\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/grive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AfpjSlhu9mta",
        "outputId": "c0291a59-444e-4b02-aa0b-0fac9abc3990"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "#Data Preprocessing and Feature Engineering\n",
        "import string\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "\n",
        "#Model Selection and Validation\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report,accuracy_score"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hCOGDIr495nl",
        "outputId": "6e9dff8f-1512-4875-cb5e-26491c86130e"
      },
      "source": [
        "data = pd.read_csv(\"/content/grive/MyDrive/labeled_data.csv\",index_col=0)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/arraysetops.py:580: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  mask |= (ar1 == a)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQvfKEHk975G",
        "outputId": "1626f243-3078-4b15-e4d8-483bd60db23c"
      },
      "source": [
        "data.info()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 1226258 entries, 0 to 1226257\n",
            "Data columns (total 5 columns):\n",
            " #   Column         Non-Null Count    Dtype  \n",
            "---  ------         --------------    -----  \n",
            " 0   publish_date   1226258 non-null  int64  \n",
            " 1   headline_text  1226258 non-null  object \n",
            " 2   Polarity       1226258 non-null  float64\n",
            " 3   Subjectivity   1226258 non-null  float64\n",
            " 4   Analysis       1226258 non-null  object \n",
            "dtypes: float64(2), int64(1), object(2)\n",
            "memory usage: 56.1+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3jPorqh-VRA",
        "outputId": "9d6e5fa5-7788-4713-c29b-9f7b3bc9b7dd"
      },
      "source": [
        "data['Analysis'].unique()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Neutral', 'Positive', 'Negative'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfPKF9xf-XNc",
        "outputId": "f4435e57-d6e8-4763-db40-86f8b7b1f2f7"
      },
      "source": [
        "print(data[data['Analysis']==\"Positive\"]['Analysis'].count())\n",
        "print(data[data['Analysis']==\"Negative\"]['Analysis'].count())\n",
        "print(data[data['Analysis']==\"Neutral\"]['Analysis'].count())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "209676\n",
            "156163\n",
            "860419\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoDCOwFv-Ybc"
      },
      "source": [
        "data['labels'] = data['Analysis'].map({'Neutral':0,'Positive':1,'Negative':-1})"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "YpMmdyu2-aFs",
        "outputId": "5c1f05c2-4d8c-438b-a5be-3b0cf6e238a9"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>publish_date</th>\n",
              "      <th>headline_text</th>\n",
              "      <th>Polarity</th>\n",
              "      <th>Subjectivity</th>\n",
              "      <th>Analysis</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20030219</td>\n",
              "      <td>aba decides against community broadcasting lic...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20030219</td>\n",
              "      <td>act fire witnesses must be aware of defamation</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>Positive</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20030219</td>\n",
              "      <td>a g calls for infrastructure protection summit</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20030219</td>\n",
              "      <td>air nz staff in aust strike for pay rise</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20030219</td>\n",
              "      <td>air nz strike to affect australian travellers</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   publish_date  ... labels\n",
              "0      20030219  ...      0\n",
              "1      20030219  ...      1\n",
              "2      20030219  ...      0\n",
              "3      20030219  ...      0\n",
              "4      20030219  ...      0\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOvRoN_9-bkq"
      },
      "source": [
        "punct =string.punctuation\n",
        "stop_words = stopwords.words('english')\n",
        "clean_data = []\n",
        "def data_preprocessing(news):\n",
        "  words =[]\n",
        "\n",
        "  for word in nltk.word_tokenize(news):\n",
        "    if word not in punct:\n",
        "        if word not in stop_words:\n",
        "          words.append(word)\n",
        "  clean_data.append(\" \".join(words))      \n",
        "  \n",
        "\n",
        "data['headline_text'].apply(data_preprocessing)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4G-IWxTv-dBT"
      },
      "source": [
        "normalize = []\n",
        "def normalization(clean_data):\n",
        "  lem = WordNetLemmatizer()\n",
        "    \n",
        "  for headline in clean_data:\n",
        "    normalized_tweet = []\n",
        "    for word in nltk.word_tokenize(headline):\n",
        "        normalized_text = lem.lemmatize(word,'v')\n",
        "        normalized_tweet.append(normalized_text)\n",
        "    normalize.append(\" \".join(normalized_tweet))\n",
        "    \n",
        "normalization(clean_data)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAvTeg9j-ehq"
      },
      "source": [
        "pipeline = Pipeline([\n",
        "    ('bow',CountVectorizer()),  # strings to token integer counts\n",
        "    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores\n",
        "    ('classifier', MultinomialNB()),  # train on TF-IDF vectors w/ Naive Bayes classifier\n",
        "])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2OepU4--f_Q"
      },
      "source": [
        "msg_train, msg_test, label_train, label_test = train_test_split(data['headline_text'], data['labels'], test_size=0.2)\n",
        "pipeline.fit(msg_train,label_train)\n",
        "predictions = pipeline.predict(msg_test)\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NuCmrvPx-hdS",
        "outputId": "b34b4219-55bf-41d2-a5ec-c08eea69beca"
      },
      "source": [
        "print(classification_report(predictions,label_test))\n",
        "print(confusion_matrix(predictions,label_test))\n",
        "print(accuracy_score(predictions,label_test))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.64      0.95      0.76     21161\n",
            "           0       1.00      0.91      0.95    189098\n",
            "           1       0.78      0.93      0.85     34993\n",
            "\n",
            "    accuracy                           0.91    245252\n",
            "   macro avg       0.80      0.93      0.85    245252\n",
            "weighted avg       0.94      0.91      0.92    245252\n",
            "\n",
            "[[ 20069    142    950]\n",
            " [  9250 171554   8294]\n",
            " [  2152    332  32509]]\n",
            "0.9138844943160505\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzAh1oXL-irP"
      },
      "source": [
        "import pickle\n",
        "filename = 'finalized_model.sav'\n",
        "pickle.dump(pipeline, open(filename, 'wb'))"
      ],
      "execution_count": 17,
      "outputs": []
    }
  ]
}